----------- Time Series Analysis for 401-500 from 2008-03-19 to 2015-09-17-----------
lag_correlations
[  1.00000000e+00  -4.94258140e-01  -3.35904019e-02   7.19909744e-03
   4.99713163e-02   1.62491445e-02  -4.84421172e-02  -2.30490975e-03
   1.97753298e-02   1.76530085e-02  -4.91549531e-02   1.42804621e-02
   1.43067429e-02   1.47926045e-03  -3.39739234e-02   1.92097839e-02
   5.06905467e-03   1.24172995e-02  -2.07324916e-02   9.72151352e-03
  -1.73680043e-02   2.66371497e-02  -1.00672687e-02  -5.58656686e-03
   1.01473887e-02  -1.04610373e-02   9.52438458e-03  -2.60384308e-02
   2.08910495e-02  -5.44107940e-04   3.51342987e-03  -5.83071343e-03
  -1.59057425e-03  -1.25537502e-02   2.08689977e-02  -1.37190178e-03
   1.49219270e-03  -5.15233093e-03  -1.03695876e-02  -3.27409445e-03
   1.74579880e-02]
lag_partial_correlations
[ 1.         -0.50121952 -0.38164951 -0.3246829  -0.21781086 -0.10379806
 -0.0992153  -0.10611634 -0.08816876 -0.03854583 -0.09060775 -0.10087244
 -0.08950859 -0.07496454 -0.12848006 -0.12997273 -0.13501341 -0.10399414
 -0.1141711  -0.09950318 -0.15924285 -0.15111789 -0.16607842 -0.19714915
 -0.21884346 -0.29607971 -0.39768127 -0.76024355 -3.13614563  1.46303462
  0.6052814   0.38919517  0.28262801  0.17502315  0.16922993  0.16866437
  0.18074811  0.16680532  0.10837822  0.03612644  0.05468414]
ARIMA_1_0_0 MAE: 34.8335217105
ARIMA_2_0_0 MAE: 34.8589979597
ARIMA_3_0_0 MAE: 33.9550602725
ARIMA_0_0_1 MAE: 34.8384585439
ARMA_3_0 MAE: 33.9550602725
ARMA_2_0 MAE: 34.8589979597
ARMA_1_0 MAE: 34.8335217105
ARMA_2_1 MAE: 34.7373843778
The best model for 401-500 based on least MAE criterion is ARIMA_3_0_0, it has an MAE of 33.955060
Using ARIMA_3_0_0 for making predictions...
predicted_Dates [numpy.datetime64('2015-10-17'), numpy.datetime64('2015-11-16'), numpy.datetime64('2015-12-16'), numpy.datetime64('2016-01-15'), numpy.datetime64('2016-02-14'), numpy.datetime64('2016-03-15'), numpy.datetime64('2016-04-14'), numpy.datetime64('2016-05-14'), numpy.datetime64('2016-06-13'), numpy.datetime64('2016-07-13'), numpy.datetime64('2016-08-12'), numpy.datetime64('2016-09-11')]
predicted_Values [ 1.09666315  1.12466163  1.09743141  1.06783531  1.09543647  1.09463078
  1.09285669  1.0940071   1.09399838  1.09390237  1.09395006  1.09395118]
                              ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                   73
Model:                     ARMA(3, 0)   Log Likelihood                -100.385
Method:                       css-mle   S.D. of innovations              0.957
Date:                Fri, 18 Dec 2015   AIC                            210.770
Time:                        07:02:24   BIC                            222.222
Sample:                             0   HQIC                           215.334
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          1.0939      0.113      9.711      0.000         0.873     1.315
ar.L1.y       -0.0125      0.117     -0.107      0.915        -0.241     0.216
ar.L2.y       -0.0215      0.116     -0.185      0.853        -0.249     0.206
ar.L3.y        0.0402      0.115      0.349      0.728        -0.186     0.266
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1           -1.3055           -2.4892j            2.8108           -0.3269
AR.2           -1.3055           +2.4892j            2.8108            0.3269
AR.3            3.1449           -0.0000j            3.1449           -0.0000
-----------------------------------------------------------------------------
