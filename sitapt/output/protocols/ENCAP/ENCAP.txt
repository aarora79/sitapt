----------- Time Series Analysis for ENCAP from 2008-03-19 to 2015-09-17-----------
lag_correlations
[  1.00000000e+00  -8.35429791e-03   2.93975144e-03  -2.83569001e-02
   3.07753913e-02  -1.31001602e-03  -1.43369071e-03   8.55514765e-04
  -3.19292292e-03  -4.06714345e-03  -6.89506364e-03   2.22492678e-03
   3.08970989e-04  -2.91153032e-03  -4.94878244e-03   1.10756263e-03
  -1.24060567e-02   1.45080629e-03   4.15795822e-04  -3.49604058e-03
  -1.02131849e-02  -7.92865542e-03  -7.41363685e-04  -3.54653912e-03
  -1.01256836e-03  -1.54022932e-02   6.72899890e-03  -5.29592455e-03
  -7.21761867e-03  -4.06693750e-03  -6.17333546e-03  -5.92577955e-03
  -6.13575673e-03  -7.09550954e-03  -7.42594562e-03  -6.02593465e-03
  -6.84751484e-03  -7.24320043e-03  -7.33518491e-03  -7.27665597e-03
  -7.98780290e-03]
lag_partial_correlations
[  1.00000000e+00  -8.47196408e-03   2.95218205e-03  -2.95416344e-02
   3.21105029e-02  -7.29771771e-04  -2.63358656e-03   2.83197593e-03
  -4.67122935e-03  -4.78316955e-03  -7.82424469e-03   2.16814218e-03
   4.41247757e-04  -3.72982504e-03  -5.58547432e-03   1.17990907e-03
  -1.62030360e-02   1.54873688e-03   1.02171790e-03  -5.87483126e-03
  -1.31569427e-02  -1.14617751e-02  -1.68326326e-03  -5.69611584e-03
  -1.59635685e-03  -2.31436163e-02   9.66598722e-03  -7.96997176e-03
  -1.34609619e-02  -5.32800443e-03  -1.23388553e-02  -1.09988843e-02
  -1.09859486e-02  -1.40849180e-02  -1.46318302e-02  -1.25957538e-02
  -1.45082427e-02  -1.59576949e-02  -1.63456990e-02  -1.71721662e-02
  -1.91378830e-02]
ARIMA_1_0_0 MAE: inf
ARIMA_2_0_0 MAE: inf
ARIMA_0_0_1 MAE: inf
ARIMA_1_0_3 MAE: inf
ARMA_2_0 MAE: inf
ARMA_1_0 MAE: inf
The best model for ENCAP based on least MAE criterion is ARIMA_1_0_0, it has an MAE of inf
Using ARIMA_1_0_0 for making predictions...
predicted_Dates [numpy.datetime64('2015-10-17'), numpy.datetime64('2015-11-16'), numpy.datetime64('2015-12-16'), numpy.datetime64('2016-01-15'), numpy.datetime64('2016-02-14'), numpy.datetime64('2016-03-15'), numpy.datetime64('2016-04-14'), numpy.datetime64('2016-05-14'), numpy.datetime64('2016-06-13'), numpy.datetime64('2016-07-13'), numpy.datetime64('2016-08-12'), numpy.datetime64('2016-09-11')]
predicted_Values [ 0.06765156  0.34236175  0.08903304  0.07259291  0.071526    0.07145676
  0.07145227  0.07145198  0.07145196  0.07145196  0.07145196  0.07145196]
                              ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                   73
Model:                     ARMA(1, 0)   Log Likelihood                 -51.926
Method:                       css-mle   S.D. of innovations              0.493
Date:                Fri, 18 Dec 2015   AIC                            109.851
Time:                        07:02:11   BIC                            116.723
Sample:                             0   HQIC                           112.589
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.0715      0.086      0.834      0.407        -0.096     0.239
ar.L1.y        0.0649      0.927      0.070      0.944        -1.752     1.882
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1           15.4092           +0.0000j           15.4092            0.0000
-----------------------------------------------------------------------------
