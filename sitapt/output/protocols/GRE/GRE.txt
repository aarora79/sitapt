----------- Time Series Analysis for GRE from 2008-03-19 to 2015-09-17-----------
lag_correlations
[  1.00000000e+00  -5.72126887e-01   1.72053318e-01  -4.19628751e-02
  -5.29974464e-02   6.92553782e-02   4.92956457e-02  -3.60942358e-02
  -8.74204339e-02   3.01707364e-02   4.56806503e-02  -4.97988890e-02
  -4.80074304e-04  -6.26417618e-02   2.34770491e-02   4.41361318e-02
  -3.45836167e-02   7.49963057e-02  -1.44417940e-01   7.84769038e-02
   2.62019532e-02   1.96188184e-02  -1.51729344e-02  -2.62580443e-02
  -1.43187680e-01   2.22872313e-01  -1.56057870e-01   1.15748354e-01
  -7.48741159e-02  -2.35410839e-02   1.85369859e-02   4.87636201e-02
  -2.64312672e-02  -8.67892055e-02   8.26397547e-02   1.43131319e-02
  -2.48220145e-03   7.40623997e-02  -1.88881421e-01   2.00603298e-01
  -1.40990095e-01]
lag_partial_correlations
[  1.00000000e+00  -5.80185012e-01  -2.40652768e-01  -8.96474995e-02
  -1.39661877e-01  -4.92750840e-02   1.38260654e-01   1.34354110e-01
  -1.10497763e-01  -1.64927417e-01   2.49747920e-03  -3.49979301e-02
  -1.40177167e-01  -2.16034106e-01  -1.30357659e-01   9.37069586e-03
  -4.99904950e-02   1.04734208e-01  -4.44222250e-02  -9.11239403e-02
  -5.77401099e-03   9.28413354e-02   4.89929691e-02  -4.96118402e-02
  -4.96420339e-01  -1.68662385e-01  -2.16522705e-01  -1.01999153e-01
  -1.70699011e-02  -3.13076474e-02  -1.18072609e-01  -6.58564208e-02
  -6.50452479e-02  -4.17197462e-01  -6.70259328e-01  -1.11667898e+00
   8.42762873e+00   9.30910688e-01   1.04409601e-01   5.66278328e-01
   2.50029057e-01]
ARIMA_1_0_0 MAE: inf
ARIMA_2_0_0 MAE: inf
ARIMA_3_0_0 MAE: inf
ARIMA_3_0_2 MAE: inf
ARIMA_2_0_2 MAE: inf
ARIMA_0_0_1 MAE: inf
ARIMA_3_0_3 MAE: inf
ARIMA_1_0_6 MAE: inf
ARIMA_1_0_3 MAE: inf
ARMA_3_0 MAE: inf
ARMA_2_0 MAE: inf
ARMA_1_0 MAE: inf
ARMA_2_1 MAE: inf
ARMA_2_3 MAE: inf
The best model for GRE based on least MAE criterion is ARIMA_1_0_0, it has an MAE of inf
Using ARIMA_1_0_0 for making predictions...
predicted_Dates [numpy.datetime64('2015-10-17'), numpy.datetime64('2015-11-16'), numpy.datetime64('2015-12-16'), numpy.datetime64('2016-01-15'), numpy.datetime64('2016-02-14'), numpy.datetime64('2016-03-15'), numpy.datetime64('2016-04-14'), numpy.datetime64('2016-05-14'), numpy.datetime64('2016-06-13'), numpy.datetime64('2016-07-13'), numpy.datetime64('2016-08-12'), numpy.datetime64('2016-09-11')]
predicted_Values [ 0.10857184  0.08343301  0.11215084  0.12262428  0.12644396  0.127837
  0.12834505  0.12853033  0.12859791  0.12862255  0.12863154  0.12863482]
                              ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                   73
Model:                     ARMA(1, 0)   Log Likelihood                  41.309
Method:                       css-mle   S.D. of innovations              0.137
Date:                Fri, 18 Dec 2015   AIC                            -76.618
Time:                        07:02:03   BIC                            -69.746
Sample:                             0   HQIC                           -73.879
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.1286      0.025      5.124      0.000         0.079     0.178
ar.L1.y        0.3647      0.109      3.352      0.001         0.151     0.578
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            2.7420           +0.0000j            2.7420            0.0000
-----------------------------------------------------------------------------
